{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a054832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from typing import List, Any\n",
    "\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef3bcfa-5843-4bb5-a236-be18190a9bee",
   "metadata": {},
   "source": [
    "## Task description\n",
    "\n",
    "The task is to create a recommendation system for a proprietary streaming service similar to Spotify.\n",
    "The goal is to improve the algorithm that will determine the most relevant recommendations for each user based on their listening history.\n",
    "\n",
    "### Data description\n",
    "\n",
    "The dataset contains only the user's listening history, without any additional information such as artist description or additional information about the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f86f3a9",
   "metadata": {},
   "source": [
    "## Dataset reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b0fc0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pl.read_parquet('train.parquet')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0187017",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb0aaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_K = 20\n",
    "\n",
    "def user_hitrate(y_relevant: List[str], y_recs: List[str], k: int = TOP_K) -> int:\n",
    "    return int(len(set(y_relevant).intersection(y_recs[:k])) > 0)\n",
    "\n",
    "def user_ndcg(y_rel: List[Any], y_rec: List[Any], k: int = 10) -> float:\n",
    "    \"\"\"\n",
    "    :param y_rel: relevant items\n",
    "    :param y_rec: recommended items\n",
    "    :param k: number of top recommended items\n",
    "    :return: ndcg metric for user recommendations\n",
    "    \"\"\"\n",
    "    dcg = sum([1. / np.log2(idx + 2) for idx, item in enumerate(y_rec[:k]) if item in y_rel])\n",
    "    idcg = sum([1. / np.log2(idx + 2) for idx, _ in enumerate(zip(y_rel, np.arange(k)))])\n",
    "    return dcg / idcg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7ba610-bb56-4938-ba20-825abdba86dd",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07829521",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Mapping strings to digits for convenience in subsequent training of algorithms\n",
    "\"\"\"\n",
    "user_mapping = {k: v for v, k in enumerate(data['user_id'].unique())}\n",
    "user_mapping_inverse = {k: v for v, k in user_mapping.items()}\n",
    "\n",
    "artist_mapping = {k: v for v, k in enumerate(data['artist_id'].unique())}\n",
    "artist_mapping_inverse = {k: v for v, k in artist_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156ede3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped_df_with_inds = (\n",
    "    data\n",
    "    .with_columns([\n",
    "        pl.col('user_id').map_elements(user_mapping.get, return_dtype=pl.Int64),\n",
    "        pl.col('artist_id').map_elements(artist_mapping.get, return_dtype=pl.Int64),\n",
    "    ])\n",
    "    # For each user, the last 3 objects are kept as test samples, and the rest are used for training.\n",
    "    .group_by('user_id')\n",
    "    .agg([\n",
    "        pl.implode('artist_id').map_elements(lambda x: x[:-3], return_dtype=pl.self_dtype()).alias('train_item_ids'),\n",
    "        pl.implode('artist_id').map_elements(lambda x: x[-3:], return_dtype=pl.self_dtype()).alias('test_item_ids'),\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dea774",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_seq_len = int(grouped_df_with_inds['train_item_ids'].map_elements(len, return_dtype=pl.Int8).median())\n",
    "print(f\"средняя длина сессии {median_seq_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e064a3aa",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "\n",
    "As a simple baseline of recommender system, the the most popular artists from training data are used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e115ef-f3b0-4929-a202-2bcdc0867ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df_with_inds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa65a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of the top atrists \n",
    "\n",
    "top_artists = (\n",
    "    grouped_df_with_inds\n",
    "    .select(pl.col('train_item_ids').alias('artist_id'))\n",
    "    .explode('artist_id')\n",
    "    .group_by('artist_id')\n",
    "    .len()\n",
    "    .sort('len', descending=True)\n",
    "    .head(TOP_K + median_seq_len)\n",
    ")['artist_id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900f8bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality evaluation\n",
    "\n",
    "ndcg_list = []\n",
    "hitrate_list = []\n",
    "\n",
    "for user_id, user_history, y_rel in grouped_df_with_inds.rows():\n",
    "    y_rec = [artist_id for artist_id in top_artists if artist_id not in user_history]\n",
    "    \n",
    "    ndcg_list.append(user_ndcg(y_rel, y_rec))\n",
    "    hitrate_list.append(user_hitrate(y_rel, y_rec))\n",
    "    \n",
    "print(f'NDCG@{TOP_K} = {np.mean(ndcg_list):.5f}, Hitrate@{TOP_K} = {np.mean(hitrate_list):.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824f7ac3",
   "metadata": {},
   "source": [
    "Не забывайте, что в файле с рекомендациями должны быть **исходные идентификаторы (строки)**, а не преобразованные в числа!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d125e1-c8d8-467d-a0bb-3097192ad13d",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104c3aed-82c0-400d-8751-d81278376ad2",
   "metadata": {},
   "source": [
    "## Main funcitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b11ee52-bcf6-4c20-9cf1-90ee6f5d05a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f9d661-6f12-43a2-969b-53c883c10951",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ndcg_list = []\n",
    "hitrate_list = []\n",
    "  \n",
    "def evaluate_model(model):\n",
    "    ndcg_list = []\n",
    "    hitrate_list = []\n",
    "    for user_id, train_ids, y_rel in grouped_df_with_inds.rows():\n",
    "        model_preds = model.predict_output_word(\n",
    "            train_ids, topn=(TOP_K + len(train_ids))\n",
    "        )\n",
    "        if model_preds is None:\n",
    "            hitrate_list.append(0)\n",
    "            continue\n",
    "\n",
    "        y_rec = [pred[0] for pred in model_preds if pred[0] not in train_ids]\n",
    "        ndcg_list.append(user_ndcg(y_rel, y_rec))\n",
    "        hitrate_list.append(user_hitrate(y_rel, y_rec))\n",
    "    return np.mean(ndcg_list), np.mean(hitrate_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a477cba-aa61-44b1-9159-e110e81e914f",
   "metadata": {},
   "source": [
    "## Training W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45e632b-b241-4b34-86d4-7eff8306f1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with default parameters\n",
    "\n",
    "set_seed(SEED)\n",
    "model = Word2Vec(grouped_df_with_inds['train_item_ids'].to_list(), **params, workers=4, epochs=10)\n",
    "mean_ndcg, mean_hitrate = evaluate_model(model)\n",
    "print(f'MAP@{TOP_K} = {mean_ndcg:.4f} Hitrate@{TOP_K} = {mean_hitrate:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cedc3d-307d-4481-b946-f8b056cc0de6",
   "metadata": {},
   "source": [
    "### Searching for best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24557573-9618-47f5-ba06-b1ecd024fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    sg = trial.suggest_categorical('sg', [0, 1])\n",
    "    window = trial.suggest_int('window', 1, 10)\n",
    "    ns_exponent = trial.suggest_float('ns_exponent', -3, 3)\n",
    "    negative = trial.suggest_int('negative', 1, 20)\n",
    "    min_count = trial.suggest_int('min_count', 0, 20)\n",
    "    vector_size = trial.suggest_categorical('vector_size', [16, 32, 64, 128])\n",
    "    \n",
    "    print({\n",
    "        'sg': sg,\n",
    "        'window_len': window,\n",
    "        'ns_exponent': ns_exponent,\n",
    "        'negative': negative,\n",
    "        'min_count': min_count,\n",
    "        'vector_size': vector_size,\n",
    "    })\n",
    "    \n",
    "    set_seed(SEED)\n",
    "    model = Word2Vec(\n",
    "        grouped_df_with_inds['train_item_ids'].to_list(),\n",
    "        window=window,\n",
    "        sg=sg,\n",
    "        hs=0,\n",
    "        min_count=min_count,\n",
    "        vector_size=vector_size,\n",
    "        negative=negative,\n",
    "        ns_exponent=ns_exponent,\n",
    "        seed=SEED,\n",
    "        epochs=5,\n",
    "    )\n",
    "    \n",
    "    mean_ndcg, mean_hitrate = evaluate_model(model)\n",
    "    print(f'MAP@{TOP_K} = {mean_ndcg:.4f} Hitrate@{TOP_K} = {mean_hitrate:.4f}')\n",
    "    return mean_hitrate\n",
    "    \n",
    "    \n",
    "study = optuna.create_study(directions=('maximize',))\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9e2fb3-c22e-4f89-94c1-ba67dae94d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the best trials\n",
    "with open(\"optuna_best_params.json\", 'w') as f:\n",
    "    json.dump(study.best_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33d2cb3-d865-453d-a62e-511661fd8027",
   "metadata": {},
   "source": [
    "# Submission preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6e0572-9937-4bd4-a568-d75d2c6d1a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = []\n",
    "df_subm = data.group_by('user_id').agg(pl.col('artist_id'))\n",
    "params = study.best_params\n",
    "\n",
    "set_seed(SEED)\n",
    "model_subm = Word2Vec(df_subm['artist_id'].to_list(), **params, workers=4, epochs=20)\n",
    "\n",
    "for user_id, user_history in df_subm.rows():\n",
    "    model_preds = model_subm.predict_output_word(\n",
    "        user_history, topn=(TOP_K + len(train_ids))\n",
    "    )\n",
    "    if model_preds is None:\n",
    "        y_rec = top_artists.copy()\n",
    "        continue\n",
    "\n",
    "    y_rec = [pred[0] for pred in model_preds if pred[0] not in user_history]\n",
    "    submission.append((user_id, y_rec))\n",
    "    \n",
    "submission = pl.DataFrame(submission, schema=('user_id', 'y_rec'), orient=\"row\")\n",
    "submission.write_parquet('submission.parquet')\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
